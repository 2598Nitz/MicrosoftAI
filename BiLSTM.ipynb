{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2598Nitz/MicrosoftAI/blob/master/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Eb9JgSwTO0Xd",
        "colab_type": "code",
        "outputId": "940fc019-80f3-46c1-f6d6-1e9b9f7c5ee8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!python -m pip install contractions"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.17)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bF50UFj8OtRF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re, string, unicodedata\n",
        "import nltk\n",
        "import contractions\n",
        "import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7sUZsRINO_Qj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def replace_contractions(text):\n",
        "    \"\"\"Replace contractions in string of text\"\"\"\n",
        "    return contractions.fix(text)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zLgRMuOrPHsZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fja4pcSRUzFc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a7RgcMuzVCAZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id':'1ui651J2qMu3uCT4YzAmKNvA2FbRu915D'}) # replace fileid with Id of file you want to access\n",
        "downloaded.GetContentFile('data.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LtM_R4--VIBX",
        "colab_type": "code",
        "outputId": "38c17a57-aa85-4d43-f3ac-e9ac4cb7aade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data.tsv', sep='\\t', names= ['query_id','query','passage','label','passage_id'])\n",
        "#pd.set_option('display.expand_frame_repr', False)\n",
        "df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>query</th>\n",
              "      <th>passage</th>\n",
              "      <th>label</th>\n",
              "      <th>passage_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>A company is incorporated in a specific nation...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Today, there is a growing community of more th...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Corporation definition, an association of indi...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>Examples of corporation in a Sentence. 1  He w...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131</td>\n",
              "      <td>. what is a corporation?</td>\n",
              "      <td>1: a government-owned corporation (as a utilit...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   query_id                     query  \\\n",
              "0       131  . what is a corporation?   \n",
              "1       131  . what is a corporation?   \n",
              "2       131  . what is a corporation?   \n",
              "3       131  . what is a corporation?   \n",
              "4       131  . what is a corporation?   \n",
              "\n",
              "                                             passage  label  passage_id  \n",
              "0  A company is incorporated in a specific nation...      0           0  \n",
              "1  Today, there is a growing community of more th...      0           1  \n",
              "2  Corporation definition, an association of indi...      0           2  \n",
              "3  Examples of corporation in a Sentence. 1  He w...      0           3  \n",
              "4  1: a government-owned corporation (as a utilit...      0           4  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "VSH1BE2IWNNp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = df.iloc[:12000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9GuhopV0RvXR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"query\"] = df[\"query\"].apply(lambda x: replace_contractions(x))\n",
        "df[\"passage\"] = df[\"passage\"].apply(lambda x: replace_contractions(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNtFV5CCXyTP",
        "colab_type": "code",
        "outputId": "1a6d3185-0f7c-476b-b1ba-d58a6dbc5a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "oNEwZSquX9Kq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"query\"] = df[\"query\"].apply(lambda x: nltk.word_tokenize(x))\n",
        "df[\"passage\"] = df[\"passage\"].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VoeXwnwIYMdx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        if word.isdigit():\n",
        "            new_word = p.number_to_words(word)\n",
        "            new_words.append(new_word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    wh_words = [\"when\",\"where\",\"why\",\"how\",\"what\",\"which\",\"who\",\"whom\",\"no\",\"nor\",\"not\"]\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english') or word in wh_words:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    return words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tadisS0PZAw7",
        "colab_type": "code",
        "outputId": "f8ff0536-1cf4-494e-afdf-970c3617a688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "metadata": {
        "id": "LWm4SX9mYc7z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"query\"] = df[\"query\"].apply(lambda x: normalize(x))\n",
        "df[\"passage\"] = df[\"passage\"].apply(lambda x: normalize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "imKgDhvbZoPs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lemmatize(words):\n",
        "    lemmas = lemmatize_verbs(words)\n",
        "    return lemmas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_SsoOlKua2GK",
        "colab_type": "code",
        "outputId": "a775b338-e4a4-419c-d30e-3a4cd13de550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "metadata": {
        "id": "1aXFUz-Uakdr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df[\"query\"] = df[\"query\"].apply(lambda x: lemmatize(x))\n",
        "df[\"passage\"] = df[\"passage\"].apply(lambda x: lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dc5nlgFNayuS",
        "colab_type": "code",
        "outputId": "6a7e5eff-e97e-4041-9c0b-199925002611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>query</th>\n",
              "      <th>passage</th>\n",
              "      <th>label</th>\n",
              "      <th>passage_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>131</td>\n",
              "      <td>[what, corporation]</td>\n",
              "      <td>[company, incorporate, specific, nation, often...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>131</td>\n",
              "      <td>[what, corporation]</td>\n",
              "      <td>[today, grow, community, two thousand, one hun...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>131</td>\n",
              "      <td>[what, corporation]</td>\n",
              "      <td>[corporation, definition, association, individ...</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>131</td>\n",
              "      <td>[what, corporation]</td>\n",
              "      <td>[examples, corporation, sentence, one, work, c...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>131</td>\n",
              "      <td>[what, corporation]</td>\n",
              "      <td>[one, governmentowned, corporation, utility, r...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   query_id                query  \\\n",
              "0       131  [what, corporation]   \n",
              "1       131  [what, corporation]   \n",
              "2       131  [what, corporation]   \n",
              "3       131  [what, corporation]   \n",
              "4       131  [what, corporation]   \n",
              "\n",
              "                                             passage  label  passage_id  \n",
              "0  [company, incorporate, specific, nation, often...      0           0  \n",
              "1  [today, grow, community, two thousand, one hun...      0           1  \n",
              "2  [corporation, definition, association, individ...      0           2  \n",
              "3  [examples, corporation, sentence, one, work, c...      0           3  \n",
              "4  [one, governmentowned, corporation, utility, r...      0           4  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "vd9cNztlhhTz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Max length of query and passage"
      ]
    },
    {
      "metadata": {
        "id": "v-NgNfUJbGJx",
        "colab_type": "code",
        "outputId": "06c7e75a-575e-4ce9-a481-b8e29543e527",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(df[\"query\"].map(lambda x: len(x)).max())\n",
        "print(df[\"passage\"].map(lambda x: len(x)).max())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "116\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJg_DurwrD2E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU, CuDNNGRU, CuDNNLSTM, BatchNormalization\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
        "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.models import Model, load_model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
        "from keras import backend as K\n",
        "from keras.engine import InputSpec, Layer\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5BvVnfyNrMF3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traindf = df.iloc[:10000,:]\n",
        "validdf = df.iloc[10000:12000,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xWSvbpz_tzVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "full_text = list(df['query'].values) + list(df['passage'].values)\n",
        "tk = Tokenizer()\n",
        "tk.fit_on_texts(full_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvNPS-gbuQjY",
        "colab_type": "code",
        "outputId": "637d8ce4-6635-4827-e5b7-ad1f70d78663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = len(tk.word_index) + 1\n",
        "print(vocab_size)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XL7wsQ3-r3vN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainq_tokenized = tk.texts_to_sequences(traindf['query'])\n",
        "validq_tokenized = tk.texts_to_sequences(validdf['query'])\n",
        "traina_tokenized = tk.texts_to_sequences(traindf['passage'])\n",
        "valida_tokenized = tk.texts_to_sequences(validdf['passage'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5andlM8kgQq-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_trainq = pad_sequences(trainq_tokenized, maxlen = 16)\n",
        "X_validq = pad_sequences(validq_tokenized, maxlen = 16)\n",
        "X_traina = pad_sequences(traina_tokenized, maxlen = 116)\n",
        "X_valida = pad_sequences(valida_tokenized, maxlen = 116)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNS-lOGt5tEj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id':'10Rtte1j-FA9kpIT1pAg67TwxtW9pD4hW'}) # replace fileid with Id of file you want to access\n",
        "downloaded.GetContentFile('glove.6B.100d.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J3e_uV4O6fil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from numpy import array\n",
        "from numpy import asarray\n",
        "from numpy import zeros"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ouVZ_CWdvRuD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load the whole embedding into memory\n",
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LXUyenIu5q-i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "embedding_matrix = zeros((vocab_size, EMBEDDING_DIM))\n",
        "for word, i in tk.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P0OQt5MkqZj6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Format of input to our model:\n",
        "1 query , 10 passages,  \n",
        "Output: Labels"
      ]
    },
    {
      "metadata": {
        "id": "ozdVvnQGq359",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xtrainq = []\n",
        "i = 1\n",
        "for query in X_trainq:\n",
        "  if i%10 == 1:\n",
        "    Xtrainq.append(query)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wR8t03VcrVfj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xtrainp1 = []\n",
        "Xtrainp2 = []\n",
        "Xtrainp3 = []\n",
        "Xtrainp4 = []\n",
        "Xtrainp5 = []\n",
        "Xtrainp6 = []\n",
        "Xtrainp7 = []\n",
        "Xtrainp8 = []\n",
        "Xtrainp9 = []\n",
        "Xtrainp10 = []\n",
        "i = 1\n",
        "for passage in X_traina:\n",
        "  if(i%10 == 1): \n",
        "    Xtrainp1.append(passage)\n",
        "  elif(i%10 == 2):\n",
        "    Xtrainp2.append(passage)\n",
        "  elif(i%10 == 3):\n",
        "    Xtrainp3.append(passage)\n",
        "  elif(i%10 == 4):\n",
        "    Xtrainp4.append(passage)\n",
        "  elif(i%10 == 5):\n",
        "    Xtrainp5.append(passage)\n",
        "  elif(i%10 == 6):\n",
        "    Xtrainp6.append(passage)\n",
        "  elif(i%10 == 7):\n",
        "    Xtrainp7.append(passage)\n",
        "  elif(i%10 == 8):\n",
        "    Xtrainp8.append(passage)\n",
        "  elif(i%10 == 9):\n",
        "    Xtrainp9.append(passage)\n",
        "  elif(i%10 == 0):\n",
        "    Xtrainp10.append(passage)\n",
        "  i = i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hqM_nBusFNX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Validation data"
      ]
    },
    {
      "metadata": {
        "id": "NyBXw780sJ1S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xvalidq = []\n",
        "i = 1\n",
        "for query in X_validq:\n",
        "  if i%10 == 1:\n",
        "    Xvalidq.append(query)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JSUK24FpsVKm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Xvalidp1 = []\n",
        "Xvalidp2 = []\n",
        "Xvalidp3 = []\n",
        "Xvalidp4 = []\n",
        "Xvalidp5 = []\n",
        "Xvalidp6 = []\n",
        "Xvalidp7 = []\n",
        "Xvalidp8 = []\n",
        "Xvalidp9 = []\n",
        "Xvalidp10 = []\n",
        "i = 1\n",
        "for passage in X_valida:\n",
        "  if(i%10 == 1): \n",
        "    Xvalidp1.append(passage)\n",
        "  elif(i%10 == 2):\n",
        "    Xvalidp2.append(passage)\n",
        "  elif(i%10 == 3):\n",
        "    Xvalidp3.append(passage)\n",
        "  elif(i%10 == 4):\n",
        "    Xvalidp4.append(passage)\n",
        "  elif(i%10 == 5):\n",
        "    Xvalidp5.append(passage)\n",
        "  elif(i%10 == 6):\n",
        "    Xvalidp6.append(passage)\n",
        "  elif(i%10 == 7):\n",
        "    Xvalidp7.append(passage)\n",
        "  elif(i%10 == 8):\n",
        "    Xvalidp8.append(passage)\n",
        "  elif(i%10 == 9):\n",
        "    Xvalidp9.append(passage)\n",
        "  elif(i%10 == 0):\n",
        "    Xvalidp10.append(passage)\n",
        "  i = i+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ZjNUiCa-Hc-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "tlabel_list = list(traindf[\"label\"].values)\n",
        "tlabels = np.array(tlabel_list,dtype = np.float32)\n",
        "Ytrain = np.reshape(tlabels,(-1,10))\n",
        "vlabel_list = list(validdf[\"label\"].values)\n",
        "vlabels = np.array(vlabel_list,dtype = np.float32)\n",
        "Yvalid = np.reshape(vlabels,(-1,10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dX31KbIQdvdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model for query"
      ]
    },
    {
      "metadata": {
        "id": "tppUGcE9duhY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "embedding_layerq = Embedding(len(tk.word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix],input_length= 16 ,trainable=False)\n",
        "embedding_layerp = Embedding(len(tk.word_index) + 1,EMBEDDING_DIM,weights=[embedding_matrix],input_length= 116 ,trainable=False)\n",
        "trainq_input = Input(shape=(16,), dtype='int32')\n",
        "trainq_emb = embedding_layerq(trainq_input)\n",
        "trainp1_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp2_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp3_input = Input(shape = (116,),dtype = 'int32') \n",
        "trainp4_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp5_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp6_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp7_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp8_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp9_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp10_input = Input(shape = (116,),dtype = 'int32')\n",
        "trainp1_emb = embedding_layerp(trainp1_input)\n",
        "trainp2_emb = embedding_layerp(trainp2_input)\n",
        "trainp3_emb = embedding_layerp(trainp3_input)\n",
        "trainp4_emb = embedding_layerp(trainp4_input)\n",
        "trainp5_emb = embedding_layerp(trainp5_input)\n",
        "trainp6_emb = embedding_layerp(trainp6_input)\n",
        "trainp7_emb = embedding_layerp(trainp7_input)\n",
        "trainp8_emb = embedding_layerp(trainp8_input)\n",
        "trainp9_emb = embedding_layerp(trainp9_input)\n",
        "trainp10_emb = embedding_layerp(trainp10_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xJSUHGyQAOLC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bilstm(layer1_dim,emb):\n",
        "  x = Bidirectional(LSTM(layer1_dim, return_sequences=True, dropout=0.25, recurrent_dropout=0.1))(emb)\n",
        "  x = GlobalMaxPool1D()(x)\n",
        "  x = Dense(20, activation=\"relu\")(x)\n",
        "  x = Dropout(0.25)(x) \n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L71QZUz7fsdI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "q_encoded = bilstm(64,trainq_emb)\n",
        "p1_encoded = bilstm(128,trainp1_emb)\n",
        "p2_encoded = bilstm(128,trainp2_emb)\n",
        "p3_encoded = bilstm(128,trainp3_emb)\n",
        "p4_encoded = bilstm(128,trainp4_emb)\n",
        "p5_encoded = bilstm(128,trainp5_emb)\n",
        "p6_encoded = bilstm(128,trainp6_emb)\n",
        "p7_encoded = bilstm(128,trainp7_emb)\n",
        "p8_encoded = bilstm(128,trainp8_emb)\n",
        "p9_encoded = bilstm(128,trainp9_emb)\n",
        "p10_encoded = bilstm(128,trainp10_emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_IES1CsBVL9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def outer_product(inputs):\n",
        "    \"\"\"\n",
        "    inputs: list of two tensors (of equal dimensions, \n",
        "        for which you need to compute the outer product\n",
        "    \"\"\"\n",
        "    x, y = inputs\n",
        "    batchSize = K.shape(x)[0]\n",
        "    outerProduct = x[:,:, newaxis] * y[:,newaxis,:]\n",
        "    outerProduct = K.reshape(outerProduct, (batchSize, -1))\n",
        "    # returns a flattened batch-wise set of tensors\n",
        "    return outerProduct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmAyYq0gFG4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "outputId": "f8cf2fd6-37fa-404a-996f-29ddeedf0a83"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Concatenate\n",
        "from keras.layers import multiply\n",
        "qp1 = multiply([q_encoded,p1_encoded])\n",
        "qp2 = multiply([q_encoded,p2_encoded])\n",
        "qp3 = multiply([q_encoded,p3_encoded])\n",
        "qp4 = multiply([q_encoded,p4_encoded])\n",
        "qp5 = multiply([q_encoded,p5_encoded])\n",
        "qp6 = multiply([q_encoded,p6_encoded])\n",
        "qp7 = multiply([q_encoded,p7_encoded])\n",
        "qp8 = multiply([q_encoded,p8_encoded])\n",
        "qp9 = multiply([q_encoded,p9_encoded])\n",
        "qp10 = multiply([q_encoded,p10_encoded])\n",
        "merged = Concatenate()([qp1,qp2,qp3,qp4,qp5,qp6,qp7,qp8,qp9,qp10])\n",
        "x = Dropout(0.25)(merged) \n",
        "x = Dense(100, activation=\"relu\")(x)\n",
        "output = Dense(10, activation = \"softmax\")(x)\n",
        "model = Model(inputs = [Xtrainq,Xtrainp1,Xtrainp2,Xtrainp3,Xtrainp4,Xtrainp5,Xtrainp6,Xtrainp7,Xtrainp8,Xtrainp9,Xtrainp10],outputs = [output])\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "input_train= [Xtrainq,Xtrainp1,Xtrainp2,Xtrainp3,Xtrainp4,Xtrainp5,Xtrainp6,Xtrainp7,Xtrainp8,Xtrainp9,Xtrainp10]\n",
        "input_valid= [Xvalidq,Xvalidp1,Xvalidp2,Xvalidp3,Xvalidp4,Xvalidp5,Xvalidp6,Xvalidp7,Xvalidp8,Xvalidp9,Xvalidp10]\n",
        "model.fit(input_train,Ytrain,validation_data = (input_valid,Yvalid), batch_size=32, epochs=10)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-88-c71f57f933d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mXtrainq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0minput_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mXtrainq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtrainp10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m# User-provided argument validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Check for redundancy in inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m             raise ValueError('The list of inputs passed to the model '\n\u001b[1;32m    149\u001b[0m                              \u001b[0;34m'is redundant. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1h3_feAbK0Sf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}