{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cleanText.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2598Nitz/MicrosoftAI/blob/master/cleanText.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "pZhabgTESNnE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "207d0cda-4e2e-4784-b0ee-5ece153dadc9"
      },
      "cell_type": "code",
      "source": [
        "!python -m pip install contractions"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading https://files.pythonhosted.org/packages/52/52/a15f0fb338a462045c7c87a35dbaeda11738c45aa9d2f5c76ac191d6adff/contractions-0.0.17-py2.py3-none-any.whl\n",
            "Installing collected packages: contractions\n",
            "Successfully installed contractions-0.0.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aT3kDpVySOcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re, string, unicodedata\n",
        "import nltk\n",
        "import contractions\n",
        "import inflect\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ed0peR-CSS8U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def replace_contractions(text):\n",
        "    \"\"\"Replace contractions in string of text\"\"\"\n",
        "    return contractions.fix(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HjlnS6iWSViO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c9EbGs6gSX61",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxKonkhtSaMe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id':'1W_trt5mu1a9tk4X2J1ARNeB2aodnkqr6'}) # replace fileid with Id of file you want to access\n",
        "downloaded.GetContentFile('df1cp.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FoAcIElqSkyb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "45ca7fd1-10dc-4eef-808d-cfc45f461e1f"
      },
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv('df1cp.csv',sep = \"\\t\")\n",
        "print(df1.head())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   query_id                    query  \\\n",
            "0       131  ['what', 'corporation']   \n",
            "1       131  ['what', 'corporation']   \n",
            "2       131  ['what', 'corporation']   \n",
            "3       131  ['what', 'corporation']   \n",
            "4       131  ['what', 'corporation']   \n",
            "\n",
            "                                             passage  label  passage_id  \n",
            "0  ['company', 'incorporate', 'specific', 'nation...      0           0  \n",
            "1  ['today', 'grow', 'community', 'two thousand, ...      0           1  \n",
            "2  ['corporation', 'definition', 'association', '...      0           2  \n",
            "3  ['examples', 'corporation', 'sentence', 'one',...      0           3  \n",
            "4  ['one', 'governmentowned', 'corporation', 'uti...      0           4  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oJAJ7AOMUNKT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def listToString(list1):\n",
        "  text = ' '.join(str(v) for v in list1)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cFY-mngxStc8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df1['query'] = df1['query'].str.replace('[\\[,\\]]|\\'', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OyeMUvg8d_Cz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df1['passage'] = df1['passage'].str.replace('[\\[,\\]]|\\'', '')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8piRZcZ0VXlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "downloaded = drive.CreateFile({'id':'1kL3dIiIYLt31mWQOhn_y3E1I8-1eYirZ'}) # replace fileid with Id of file you want to access\n",
        "downloaded.GetContentFile('check_point.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JpVSp3zlemVX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('check_point.csv', sep = '\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXrhW6dWfpnd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d07b8173-c994-4732-fe25-eee355f228f0"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5241880, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "2EZjSm_NfEGN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df15 = df.iloc[700000:750000,:].copy()\n",
        "df16 = df.iloc[750000:800000,:].copy()\n",
        "df17 = df.iloc[800000:850000,:].copy()\n",
        "df18 = df.iloc[850000:900000,:].copy()\n",
        "df19 = df.iloc[900000:950000,:].copy()\n",
        "df20 = df.iloc[950000:1000000,:].copy()\n",
        "df21 = df.iloc[1000000:1050000,:].copy()\n",
        "df22 = df.iloc[1050000:1100000,:].copy()\n",
        "df23 = df.iloc[1100000:1150000,:].copy()\n",
        "df24 = df.iloc[1150000:1200000,:].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "go5K9kmIfxSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "1d28062e-19c8-4417-9a28-d8fe2420fd24"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "oI6nV_OigNaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a47964f3-b8fd-4813-ba39-912287104579"
      },
      "cell_type": "code",
      "source": [
        "df15.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>query</th>\n",
              "      <th>passage</th>\n",
              "      <th>label</th>\n",
              "      <th>passage_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>700000</th>\n",
              "      <td>482885</td>\n",
              "      <td>where is the soul located in the body?</td>\n",
              "      <td>The soul is the body or person as a whole: The...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700001</th>\n",
              "      <td>482885</td>\n",
              "      <td>where is the soul located in the body?</td>\n",
              "      <td>The mind is in the brain   2nd ANSWER :   The ...</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700002</th>\n",
              "      <td>477118</td>\n",
              "      <td>where is minersville utah</td>\n",
              "      <td>Welcome to an Engaged Community. there is a be...</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700003</th>\n",
              "      <td>477118</td>\n",
              "      <td>where is minersville utah</td>\n",
              "      <td>Boating, year-round fishing and camping make M...</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>700004</th>\n",
              "      <td>477118</td>\n",
              "      <td>where is minersville utah</td>\n",
              "      <td>Beaver County, UT - Official Website - Minersv...</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        query_id                                   query  \\\n",
              "700000    482885  where is the soul located in the body?   \n",
              "700001    482885  where is the soul located in the body?   \n",
              "700002    477118               where is minersville utah   \n",
              "700003    477118               where is minersville utah   \n",
              "700004    477118               where is minersville utah   \n",
              "\n",
              "                                                  passage  label  passage_id  \n",
              "700000  The soul is the body or person as a whole: The...      0           4  \n",
              "700001  The mind is in the brain   2nd ANSWER :   The ...      0           7  \n",
              "700002  Welcome to an Engaged Community. there is a be...      0           5  \n",
              "700003  Boating, year-round fishing and camping make M...      0           3  \n",
              "700004  Beaver County, UT - Official Website - Minersv...      0           7  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Ih_ZJO5ff6no",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df15[\"query\"] = df15[\"query\"].apply(lambda x: nltk.word_tokenize(x))\n",
        "df15[\"passage\"] = df15[\"passage\"].apply(lambda x: nltk.word_tokenize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8KHQkM6gZtN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_non_ascii(words):\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def to_lowercase(words):\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = word.lower()\n",
        "        new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def remove_punctuation(words):\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
        "        if new_word != '':\n",
        "            new_words.append(new_word)\n",
        "    return new_words\n",
        "\n",
        "def replace_numbers(words):\n",
        "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
        "    p = inflect.engine()\n",
        "    new_words = []\n",
        "    for word in words:\n",
        "        try:\n",
        "            if word.isdigit():\n",
        "                new_word = p.number_to_words(word)\n",
        "                new_words.append(new_word)\n",
        "        except:\n",
        "            new_words.append(word)\n",
        "        else:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def remove_stopwords(words):\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\n",
        "    new_words = []\n",
        "    wh_words = [\"when\",\"where\",\"why\",\"how\",\"what\",\"which\",\"who\",\"whom\",\"no\",\"nor\",\"not\"]\n",
        "    for word in words:\n",
        "        if word not in stopwords.words('english') or word in wh_words:\n",
        "            new_words.append(word)\n",
        "    return new_words\n",
        "\n",
        "def stem_words(words):\n",
        "    \"\"\"Stem words in list of tokenized words\"\"\"\n",
        "    stemmer = LancasterStemmer()\n",
        "    stems = []\n",
        "    for word in words:\n",
        "        stem = stemmer.stem(word)\n",
        "        stems.append(stem)\n",
        "    return stems\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    \"\"\"Lemmatize verbs in list of tokenized words\"\"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "def normalize(words):\n",
        "    words = remove_non_ascii(words)\n",
        "    words = to_lowercase(words)\n",
        "    words = remove_punctuation(words)\n",
        "    words = replace_numbers(words)\n",
        "    words = remove_stopwords(words)\n",
        "    return words\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bgVYaG1gCzA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df15[\"query\"] = df15[\"query\"].apply(lambda x: normalize(x))\n",
        "df15[\"passage\"] = df15[\"passage\"].apply(lambda x: normalize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gBol5Qaxghp7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def lemmatize(words):\n",
        "    lemmas = lemmatize_verbs(words)\n",
        "    return lemmas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mqZFUG6NnK0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "46db1d67-e88b-4954-c711-f708fabf5c20"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "ih_VVY-Sgmlp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df15[\"query\"] = df15[\"query\"].apply(lambda x: lemmatize(x))\n",
        "df15[\"passage\"] = df15[\"passage\"].apply(lambda x: lemmatize(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y3OiHV8Ggu1C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df15.to_csv('df15cp.csv', sep = '\\t', index = False)\n",
        "from google.colab import files\n",
        "files.download('df15cp.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OCoAVPhHhNbj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}